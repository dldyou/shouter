{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Hello everyone, my name is Kim Hyun-won. We have to do some project. Yeah, this is a sample MP3 file for above project.\n"
     ]
    }
   ],
   "source": [
    "import whisper as ws\n",
    "\n",
    "model = ws.load_model(\"base\")\n",
    "\n",
    "#이걸 구해야 할건디,,,,\n",
    "audio = ws.load_audio(\"test2.m4a\")\n",
    "audio = ws.pad_or_trim(audio)\n",
    "\n",
    "mel = ws.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f'Detected language: {max(probs, key=probs.get)}')\n",
    "\n",
    "options = ws.DecodingOptions()\n",
    "result = ws.decode(model, mel, options)\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA device detection test\n",
    "import os\n",
    "import torch\n",
    "\n",
    "device_count = torch.cuda.device_count()\n",
    "\n",
    "for i in range(device_count):\n",
    "    device = torch.device(f\"cuda:{i}\")\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(device)}\")\n",
    "    print(torch.cuda.get_device_properties(device).total_memory / 1024**3, ' GB')\n",
    "    print(torch.cuda.get_device_properties(device).total_memory / 1024**3, ' GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 메모리 사용량 (bytes): 5967801856\n"
     ]
    }
   ],
   "source": [
    "# VRAM stress test\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# load ResNet-152 model\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "# move model into GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "# set large batch size\n",
    "batch_size = 32\n",
    "\n",
    "# generate input data\n",
    "input_data = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "\n",
    "# run\n",
    "output = model(input_data)\n",
    "\n",
    "# output\n",
    "print(\"GPU 메모리 사용량 (bytes):\", torch.cuda.max_memory_allocated(device=device))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\speed\\anaconda3\\envs\\shouter\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "Processor count: 12\n",
      "Memory: 15 GB\n",
      "CUDA Device 0: NVIDIA GeForce MX550\n",
      "Detected language: ko\n",
      "0.0 ~ 1.96:  여러분 안녕하십니까.\n",
      "1.96 ~ 5.68:  백화점, 대형마트, 그리고 식당과 카페, 이제는\n",
      "5.68 ~ 9.36:  방역패스 없이는 가기 어려운 곳들입니다.\n",
      "9.36 ~ 12.96:  특히 백화점과 대형마트는 오늘부터 방역패스가\n",
      "12.96 ~ 14.12:  적용됐습니다.\n",
      "14.12 ~ 16.76:  일단 일주일 동안 적응 기간을 두고 다음 주\n",
      "16.76 ~ 20.2:  월요일부터는 과태료나 영업정지 처분을 받게\n",
      "20.2 ~ 21.32:  됩니다.\n",
      "21.32 ~ 23.84:  적용 첫날 분위기, 현장에 나가 있는 취재기자\n",
      "23.84 ~ 27.0:  연결해서 알아보겠습니다.\n",
      "27.0 ~ 29.72:  이지은 기자, 낮에 사람이 많은 시간에는 평소보다\n",
      "282.53998 sec\n"
     ]
    }
   ],
   "source": [
    "# performance test - GPU mode\n",
    "import whisper as ws\n",
    "import torch, time, platform, psutil\n",
    "\n",
    "def get_device_info():\n",
    "    print(f'CPU: {platform.processor()}')\n",
    "    print(f'Processor count: {psutil.cpu_count(logical=False)}')\n",
    "    print(f'Memory: {psutil.virtual_memory().total // (1024**3)} GB')\n",
    "    \n",
    "    device_count = torch.cuda.device_count()\n",
    "\n",
    "    for i in range(device_count):\n",
    "        device = torch.device(f'cuda:{i}')\n",
    "        print(f'CUDA Device {i}: {torch.cuda.get_device_name(device)}')\n",
    "\n",
    "def start(path):\n",
    "    #모델 불러오기\n",
    "    model = ws.load_model(\"medium\")\n",
    "    \n",
    "    # 오디오 불러오기 및 trim 진행\n",
    "    audio = ws.load_audio(path)\n",
    "    audio = ws.pad_or_trim(audio)\n",
    "\n",
    "    mel = ws.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f'Detected language: {max(probs, key=probs.get)}')\n",
    "\n",
    "    options = ws.DecodingOptions(fp16 = False)\n",
    "    # result = ws.decode(model, mel, options)\n",
    "    result = model.transcribe(audio)\n",
    "\n",
    "    #print(type(result))\n",
    "    # print(result['segments'])\n",
    "    \n",
    "    ret = []\n",
    "    for data in result['segments']:\n",
    "        start_time = round(data['start'], 2)\n",
    "        end_time = round(data['end'], 2)\n",
    "        text = data['text']\n",
    "        ret.append([start_time, end_time, text])\n",
    "        \n",
    "        print(f'{start_time} ~ {end_time}: {text}')\n",
    "        \n",
    "    return ret\n",
    "\n",
    "#run task\n",
    "get_device_info()\n",
    "start_t = time.time()\n",
    "start('audio.mp3')\n",
    "end_t = time.time()\n",
    "print(f'{end_t - start_t:.5f} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\speed\\anaconda3\\envs\\shouter-cpu\\lib\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU: Intel64 Family 6 Model 154 Stepping 3, GenuineIntel\n",
      "Processor count: 12\n",
      "Memory: 15 GB\n",
      "Detected language: ko\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\speed\\anaconda3\\envs\\shouter-cpu\\lib\\site-packages\\whisper\\transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 ~ 1.96:  여러분 안녕하십니까.\n",
      "1.96 ~ 5.68:  백화점, 대형마트, 그리고 식당과 카페, 이제는\n",
      "5.68 ~ 9.36:  방역패스 없이는 가기 어려운 곳들입니다.\n",
      "9.36 ~ 12.96:  특히 백화점과 대형마트는 오늘부터 방역패스가\n",
      "12.96 ~ 14.12:  적용됐습니다.\n",
      "14.12 ~ 16.76:  일단 일주일 동안 적응 기간을 두고 다음 주\n",
      "16.76 ~ 20.2:  월요일부터는 과태료나 영업정지 처분을 받게\n",
      "20.2 ~ 21.32:  됩니다.\n",
      "21.32 ~ 23.84:  적용 첫날 분위기, 현장에 나가 있는 취재기자\n",
      "23.84 ~ 27.0:  연결해서 알아보겠습니다.\n",
      "27.0 ~ 29.72:  이지은 기자, 낮에 사람이 많은 시간에는 평소보다\n",
      "201.75114 sec\n"
     ]
    }
   ],
   "source": [
    "# performance test - CPU mode\n",
    "import platform, psutil, time\n",
    "import whisper as ws\n",
    "\n",
    "def get_device_info():\n",
    "    print(f'CPU: {platform.processor()}')\n",
    "    print(f'Processor count: {psutil.cpu_count(logical=False)}')\n",
    "    print(f'Memory: {psutil.virtual_memory().total // (1024**3)} GB')\n",
    "\n",
    "def start(path):\n",
    "    #모델 불러오기\n",
    "    model = ws.load_model(\"medium\")\n",
    "    \n",
    "    # 오디오 불러오기 및 trim 진행\n",
    "    audio = ws.load_audio(path)\n",
    "    audio = ws.pad_or_trim(audio)\n",
    "\n",
    "    mel = ws.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f'Detected language: {max(probs, key=probs.get)}')\n",
    "\n",
    "    options = ws.DecodingOptions(fp16 = False)\n",
    "    # result = ws.decode(model, mel, options)\n",
    "    result = model.transcribe(audio)\n",
    "\n",
    "    #print(type(result))\n",
    "    # print(result['segments'])\n",
    "    \n",
    "    ret = []\n",
    "    for data in result['segments']:\n",
    "        start_time = round(data['start'], 2)\n",
    "        end_time = round(data['end'], 2)\n",
    "        text = data['text']\n",
    "        ret.append([start_time, end_time, text])\n",
    "        \n",
    "        print(f'{start_time} ~ {end_time}: {text}')\n",
    "        \n",
    "    return ret\n",
    "\n",
    "#run task\n",
    "get_device_info()\n",
    "start_t = time.time()\n",
    "start('audio.mp3')\n",
    "end_t = time.time()\n",
    "print(f'{end_t - start_t:.5f} sec')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Hello everyone, my name is Kim Hyun-won. We have to do some project. Yeah, this is a sample MP3 file for above project.\n"
     ]
    }
   ],
   "source": [
    "import whisper as ws\n",
    "\n",
    "model = ws.load_model(\"base\")\n",
    "\n",
    "#이걸 구해야 할건디,,,,\n",
    "audio = ws.load_audio(\"test2.m4a\")\n",
    "audio = ws.pad_or_trim(audio)\n",
    "\n",
    "mel = ws.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f'Detected language: {max(probs, key=probs.get)}')\n",
    "\n",
    "options = ws.DecodingOptions()\n",
    "result = ws.decode(model, mel, options)\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CUDA device detection test\n",
    "import os\n",
    "import torch\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "device_count = torch.cuda.device_count()\n",
    "\n",
    "for i in range(device_count):\n",
    "    device = torch.device(f\"cuda:{i}\")\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(device)}\")\n",
    "    print(torch.cuda.get_device_properties(device).total_memory / 1024**3, ' GB')\n",
    "    print(torch.cuda.get_device_properties(device).total_memory / 1024**3, ' GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 메모리 사용량 (bytes): 5967801856\n"
     ]
    }
   ],
   "source": [
    "# VRAM stress test\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "# load ResNet-152 model\n",
    "model = models.resnet152(pretrained=True)\n",
    "\n",
    "# move model into GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)\n",
    "\n",
    "# set large batch size\n",
    "batch_size = 32\n",
    "\n",
    "# generate input data\n",
    "input_data = torch.randn(batch_size, 3, 224, 224).to(device)\n",
    "\n",
    "# run\n",
    "output = model(input_data)\n",
    "\n",
    "# output\n",
    "print(\"GPU 메모리 사용량 (bytes):\", torch.cuda.max_memory_allocated(device=device))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

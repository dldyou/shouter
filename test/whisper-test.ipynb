{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\speed\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\whisper\\timing.py:58: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  def backtrace(trace: np.ndarray):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "Hello everyone, my name is Kim Hyun-won. We have to do some project. Yeah, this is a sample MP3 file for above project.\n"
     ]
    }
   ],
   "source": [
    "import whisper as ws\n",
    "\n",
    "model = ws.load_model(\"base\")\n",
    "\n",
    "#이걸 구해야 할건디,,,,\n",
    "audio = ws.load_audio(\"test2.m4a\")\n",
    "audio = ws.pad_or_trim(audio)\n",
    "\n",
    "mel = ws.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "_, probs = model.detect_language(mel)\n",
    "print(f'Detected language: {max(probs, key=probs.get)}')\n",
    "\n",
    "options = ws.DecodingOptions()\n",
    "result = ws.decode(model, mel, options)\n",
    "\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: NVIDIA GeForce MX550\n",
      "1.999755859375  GB\n",
      "1.999755859375  GB\n"
     ]
    }
   ],
   "source": [
    "#CUDA device detection test\n",
    "import torch\n",
    "device_count = torch.cuda.device_count()\n",
    "\n",
    "for i in range(device_count):\n",
    "    device = torch.device(f\"cuda:{i}\")\n",
    "    print(f\"Device {i}: {torch.cuda.get_device_name(device)}\")\n",
    "    print(torch.cuda.get_device_properties(device).total_memory / 1024**3, ' GB')\n",
    "    print(torch.cuda.get_device_properties(device).total_memory / 1024**3, ' GB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
